import { NextRequest, NextResponse } from 'next/server'
import { BmwProfileKey, BMW_PROFILES } from '@/app/utils/bwmProfiles.util'
import { CarCondition, ServiceLocation } from '@/app/utils/calc.util'

// GLM API Configuration
const GLM_API_KEY = process.env.GLM_API_KEY
const GLM_API_URL = 'https://api.z.ai/api/coding/paas/v4/chat/completions'
const GLM_MODEL = process.env.GLM_MODEL

export type AnalysisPayload = {
  modelKey: BmwProfileKey
  year: number
  mileageKm: number
  kmPerMonth: number
  monthlyIncome: number
  annualIncome: number
  carPrice: number
  downPaymentAmount: number
  months: number
  interestAprFlat: number
  fuelPrice: number
  kmPerLiter: number
  insurancePerYear: number
  taxAndActPerYear: number
  parkingTollPerMonth: number
  holdYears: number
  depreciationRatePerYear: number
  carCondition: CarCondition
  serviceLocation: ServiceLocation
  // Calculated results
  totalPerMonth: number
  paymentPerMonth: number
  fuelCostPerMonth: number
  maintenancePerMonth: number
  depreciationPerMonth: number
  fixedCostsPerMonth: number
  ratioToIncome: number
  affordabilityLevel: '‡πÑ‡∏´‡∏ß' | '‡∏ï‡∏∂‡∏á' | '‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á'
}

export type AnalysisResult = {
  verdict: '‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠' | '‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á' | '‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠'
  confidence: number // 0-100
  summary: string
  detailedAnalysis: string
  risks: string[]
  recommendations: string[]
  comparisonWithStandard: string
}

export async function POST(request: NextRequest) {
  try {
    // Validate API key
    if (!GLM_API_KEY) {
      return NextResponse.json({ error: 'GLM_API_KEY not configured' }, { status: 500 })
    }

    // Parse request body
    const body: AnalysisPayload = await request.json()
    const {
      modelKey,
      year,
      mileageKm,
      kmPerMonth,
      monthlyIncome,
      annualIncome,
      carPrice,
      downPaymentAmount,
      months,
      interestAprFlat,
      fuelPrice,
      kmPerLiter,
      carCondition,
      serviceLocation,
      totalPerMonth,
      paymentPerMonth,
      fuelCostPerMonth,
      maintenancePerMonth,
      depreciationPerMonth,
      fixedCostsPerMonth,
      ratioToIncome,
      affordabilityLevel,
    } = body

    const profile = BMW_PROFILES[modelKey]
    const carAge = new Date().getFullYear() - year

    // Build prompt for GLM
    const prompt = `‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÅ‡∏•‡∏∞‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå BMW ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢

## ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏ã‡∏∑‡πâ‡∏≠
- ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: ${monthlyIncome.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏ï‡πà‡∏≠‡∏õ‡∏µ: ${annualIncome.toLocaleString()} ‡∏ö‡∏≤‡∏ó

## ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡∏∑‡πâ‡∏≠
- ‡∏£‡∏∏‡πà‡∏ô: ${profile.displayName}
- ‡∏≠‡∏≤‡∏¢‡∏∏‡∏£‡∏ñ: ${carAge} ‡∏õ‡∏µ (‡∏õ‡∏µ ${year})
- ‡πÑ‡∏°‡∏•‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: ${mileageKm.toLocaleString()} km
- ‡∏™‡∏†‡∏≤‡∏û‡∏£‡∏ñ: ${carCondition === 'excellent' ? '‡∏î‡∏µ‡∏°‡∏≤‡∏Å' : carCondition === 'normal' ? '‡∏õ‡∏Å‡∏ï‡∏¥' : '‡πÇ‡∏ó‡∏£‡∏°'}
- ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ã‡∏∑‡πâ‡∏≠: ${carPrice.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏î‡∏≤‡∏ß‡∏ô‡πå: ${downPaymentAmount.toLocaleString()} ‡∏ö‡∏≤‡∏ó (${((downPaymentAmount / carPrice) * 100).toFixed(0)}%)
- ‡∏ú‡πà‡∏≠‡∏ô: ${months} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- ‡∏î‡∏≠‡∏Å‡πÄ‡∏ö‡∏µ‡πâ‡∏¢: ${interestAprFlat}% ‡∏ï‡πà‡∏≠‡∏õ‡∏µ (Flat Rate)

## ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô: ${kmPerMonth} km
- ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏™‡∏¥‡πâ‡∏ô‡πÄ‡∏õ‡∏•‡∏∑‡∏≠‡∏á: ${kmPerLiter} km/L
- ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô: ${fuelPrice} ‡∏ö‡∏≤‡∏ó/‡∏•‡∏¥‡∏ï‡∏£
- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡πà‡∏≠‡∏°: ${serviceLocation === 'center' ? '‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£' : '‡∏≠‡∏π‡πà‡∏ô‡∏≠‡∏Å'}

## ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ
- ‡∏Ñ‡πà‡∏≤‡∏á‡∏ß‡∏î‡∏£‡∏ñ: ${paymentPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô: ${fuelCostPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏Ñ‡πà‡∏≤‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤: ${maintenancePerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏Ñ‡πà‡∏≤‡πÄ‡∏™‡∏∑‡πà‡∏≠‡∏°‡∏£‡∏≤‡∏Ñ‡∏≤: ${depreciationPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô+‡∏†‡∏≤‡∏©‡∏µ+‡∏à‡∏≠‡∏î): ${fixedCostsPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó
- **‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: ${totalPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô**

## ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
- ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ: ${(ratioToIncome * 100).toFixed(1)}%
- ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°: ${affordabilityLevel}

## ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ ${monthlyIncome.toLocaleString()} ‡∏ö‡∏≤‡∏ó/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏£‡∏ñ ${totalPerMonth.toLocaleString()} ‡∏ö‡∏≤‡∏ó/‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏Ñ‡∏¥‡∏î‡πÄ‡∏õ‡πá‡∏ô ${(ratioToIncome * 100).toFixed(1)}% ‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ)

1. ‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ñ‡∏Ñ‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡∏ó‡∏≥‡πÑ‡∏°?
2. ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á?
3. ‡∏°‡∏µ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°?
4. ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "${affordabilityLevel}" ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏≤‡∏Å‡∏ã‡∏∑‡πâ‡∏≠ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á?

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON:
{
  "verdict": "‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠" | "‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á" | "‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ã‡∏∑‡πâ‡∏≠",
  "confidence": ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç 0-100 (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö),
  "summary": "‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏±‡πâ‡∏ô‡πÜ 1-2 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏†‡∏≤‡∏©‡∏≤‡∏û‡∏π‡∏î",
  "detailedAnalysis": "‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•",
  "risks": ["‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á1", "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á2", ...],
  "recommendations": ["‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥1", "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥2", ...],
  "comparisonWithStandard": "‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡∏¥‡∏ô 20-30% ‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ)"
}

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å JSON`

    // Call GLM API
    const response = await fetch(GLM_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${GLM_API_KEY}`,
      },
      body: JSON.stringify({
        model: GLM_MODEL,
        messages: [
          {
            role: 'system',
            content:
              '‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå BMW ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå',
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: 0.4,
        max_tokens: 1500,
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('GLM API error:', errorText)
      return NextResponse.json(
        { error: 'GLM API request failed', details: errorText },
        { status: 502 },
      )
    }

    const data = await response.json()
    const message = data.choices?.[0]?.message
    const content = message?.content
    const reasoningContent = message?.reasoning_content

    console.log('üìù GLM Response received')
    console.log('  content length:', content ? content.length : 0)

    // Try to parse JSON from content
    let analysisResult: AnalysisResult
    try {
      // Try to extract JSON if wrapped in markdown code block
      const jsonMatch =
        content.match(/```json\s*([\s\S]*?)```/) ||
        content.match(/```\s*([\s\S]*?)```/) || [null, content]

      const jsonStr = jsonMatch[1].trim()
      analysisResult = JSON.parse(jsonStr)
    } catch {
      console.error('Failed to parse GLM response:', content)
      
      // If parsing fails, try to extract from reasoning_content
      if (reasoningContent) {
        console.log('Trying to parse from reasoning_content...')
        // Return a fallback with the raw reasoning
        return NextResponse.json({
          analysisResult: {
            verdict: '‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á',
            confidence: 50,
            summary: '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°',
            detailedAnalysis: reasoningContent,
            risks: ['‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ'],
            recommendations: ['‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô'],
            comparisonWithStandard: '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏î‡πâ',
          },
          model: GLM_MODEL,
          timestamp: new Date().toISOString(),
          note: 'Parsed from reasoning',
        })
      }
      
      return NextResponse.json(
        { error: 'Failed to parse AI response', rawContent: content },
        { status: 502 },
      )
    }

    // Ensure all required fields exist
    if (!analysisResult.verdict) analysisResult.verdict = '‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á'
    if (!analysisResult.confidence) analysisResult.confidence = 50
    if (!analysisResult.summary) analysisResult.summary = '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô'
    if (!analysisResult.detailedAnalysis) analysisResult.detailedAnalysis = ''
    if (!analysisResult.risks) analysisResult.risks = []
    if (!analysisResult.recommendations) analysisResult.recommendations = []
    if (!analysisResult.comparisonWithStandard) analysisResult.comparisonWithStandard = ''

    console.log('‚úÖ Analysis completed:', analysisResult.verdict)

    return NextResponse.json({
      analysisResult,
      model: GLM_MODEL,
      timestamp: new Date().toISOString(),
    })
  } catch (error) {
    console.error('API error:', error)
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}
